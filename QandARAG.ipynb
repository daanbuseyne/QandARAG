{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "056d934e-fd80-49cc-89fe-13bc1b3fadea",
   "metadata": {},
   "source": [
    "# Q and A with RAG\n",
    "\n",
    "In this notebook is a first dive into RAG. We will implement a general RAG system for a Q and A system and use it on 2 types of data: the hf Wikipedia data set and a joke dataset. Next we will evluate how it works and when it could be usefull. I based this notebook on the langchain handbook of the pinecone website :https://www.pinecone.io/learn/series/langchain/langchain-intro/\n",
    "\n",
    "\n",
    "General RAG system:\n",
    "1. Load llm (ollama's phi 3)\n",
    "2. Load datasets\n",
    "3. Tokenization: large textfiles (like wiki) need to be splitted before we tokenize.\n",
    "4. Embed the text files (I use the hf all-MiniLM-l6-v2)\n",
    "5. Make the vectordatabase. I use Pinecone.\n",
    "6. QandA Retrieval\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53735610-bb9b-4fde-bd40-d4087e8b8739",
   "metadata": {},
   "source": [
    "## Load LLM: Ollama: phi3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb9b872e-8616-43cc-b8e8-ff676b951c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ollama in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (0.3.0)\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from ollama) (0.27.0)\n",
      "Requirement already satisfied: anyio in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (4.1.0)\n",
      "Requirement already satisfied: certifi in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (2023.7.22)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.0.5)\n",
      "Requirement already satisfied: idna in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (3.4)\n",
      "Requirement already satisfied: sniffio in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama) (0.14.0)\n",
      "Requirement already satisfied: langchain in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (0.2.11)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from langchain) (2.0.31)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from langchain) (3.9.5)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.23 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from langchain) (0.2.26)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from langchain) (0.2.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from langchain) (0.1.93)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from langchain) (1.26.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from langchain) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.23->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.23->langchain) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.23->langchain) (4.9.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.23->langchain) (2.1)\n",
      "Requirement already satisfied: langchain_community in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (0.2.10)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from langchain_community) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from langchain_community) (2.0.31)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from langchain_community) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: langchain<0.3.0,>=0.2.9 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from langchain_community) (0.2.11)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.23 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from langchain_community) (0.2.26)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from langchain_community) (0.1.93)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from langchain_community) (1.26.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from langchain_community) (8.5.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from langchain<0.3.0,>=0.2.9->langchain_community) (0.2.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from langchain<0.3.0,>=0.2.9->langchain_community) (2.8.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.23->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.23->langchain_community) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.23->langchain_community) (4.9.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain_community) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain_community) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain_community) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain_community) (2023.7.22)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.23->langchain_community) (2.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.9->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.9->langchain_community) (2.20.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: datasets in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (2.20.0)\n",
      "Requirement already satisfied: filelock in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from datasets) (1.26.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from datasets) (2.1.4)\n",
      "Requirement already satisfied: requests>=2.32.2 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from datasets) (4.66.4)\n",
      "Requirement already satisfied: xxhash in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2023.12.2)\n",
      "Requirement already satisfied: aiohttp in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from datasets) (0.24.2)\n",
      "Requirement already satisfied: packaging in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from huggingface-hub>=0.21.2->datasets) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2023.7.22)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: transformers in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (4.43.3)\n",
      "Requirement already satisfied: filelock in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from transformers) (0.24.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from transformers) (1.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from transformers) (0.4.1)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2023.12.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: langchain_huggingface in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (0.0.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from langchain_huggingface) (0.24.2)\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.1.52 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from langchain_huggingface) (0.2.26)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.0 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from langchain_huggingface) (3.0.1)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from langchain_huggingface) (0.19.1)\n",
      "Requirement already satisfied: transformers>=4.39.0 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from langchain_huggingface) (4.43.3)\n",
      "Requirement already satisfied: filelock in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (2023.12.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (6.0.1)\n",
      "Requirement already satisfied: requests in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (4.9.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from langchain-core<0.3,>=0.1.52->langchain_huggingface) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from langchain-core<0.3,>=0.1.52->langchain_huggingface) (0.1.93)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from langchain-core<0.3,>=0.1.52->langchain_huggingface) (2.8.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from langchain-core<0.3,>=0.1.52->langchain_huggingface) (8.5.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (2.1.1)\n",
      "Requirement already satisfied: numpy in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.26.2)\n",
      "Requirement already satisfied: scikit-learn in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.5.1)\n",
      "Requirement already satisfied: scipy in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.14.0)\n",
      "Requirement already satisfied: Pillow in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (10.1.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from transformers>=4.39.0->langchain_huggingface) (2023.12.25)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from transformers>=4.39.0->langchain_huggingface) (0.4.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.52->langchain_huggingface) (2.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.1.52->langchain_huggingface) (3.10.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.52->langchain_huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.52->langchain_huggingface) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (2023.7.22)\n",
      "Requirement already satisfied: sympy in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.1.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from sympy->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ollama\n",
    "!pip install langchain\n",
    "!pip install langchain_community\n",
    "!pip install datasets\n",
    "!pip install transformers\n",
    "!pip install langchain_huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed402c67-12f7-4e3c-b2c0-b3967c8ab70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cab42575-65fd-43e6-b66b-c6677c6799f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A fundamental question in the realm of quantum computing!\n",
      "\n",
      "A qubit (quantum bit) is the basic unit of quantum information, similar to a classical bit (0 or 1). However, unlike classical bits, which can only exist in one of two states (0 or 1), qubits can exist in multiple states simultaneously, known as superposition. This means that a qubit can represent both 0 and 1 at the same time!\n",
      "\n",
      "In other words, a qubit is a quantum-mechanical version of a classical bit that uses the principles of quantum mechanics to process information. Qubits are designed to take advantage of the strange behavior of particles at the atomic level, such as superposition, entanglement, and interference.\n",
      "\n",
      "Here's a simple analogy to help illustrate the concept:\n",
      "\n",
      "Imagine you have two envelopes, each containing either 0 or 1. A classical bit would be like opening one envelope and finding either 0 or 1 inside. A qubit is like having an envelope that contains both 0 and 1 at the same time! When you open it, the contents can collapse to either 0 or 1, but until then, it's in a state of superposition.\n",
      "\n",
      "Qubits are typically represented by a mathematical construct called a wave function, which describes the possible states of the qubit. In a classical computer, bits are represented as electrical signals (high or low voltage), whereas qubits are represented as quantum-mechanical properties, such as spin or polarization.\n",
      "\n",
      "The ability to exist in multiple states at once is what allows qubits to perform certain calculations much faster than classical computers. This property, known as quantum parallelism, is the foundation of quantum computing and has significant implications for fields like cryptography, optimization, and machine learning.\n",
      "\n",
      "In summary, a qubit is a fundamental component of quantum information that can exist in multiple states simultaneously, allowing it to process information in ways that are not possible with classical bits.\n"
     ]
    }
   ],
   "source": [
    "response = ollama.generate(model='llama3',\n",
    "prompt='what is a qubit?')\n",
    "print(response['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9383651d-9b5d-4dba-b4b0-c40e635db661",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A qubit, or quantum bit, represents the fundamental unit of information in quantum computing. Unlike classical bits that can be either 0 or 1 (but not both at once), a qubit can exist simultaneously in multiple states due to superposition—a key principle of quantum mechanics known as 'quantum parallelism'. This property allows for more complex and powerful computations than traditional binary systems, especially when coupled with another phenomenon called entanglement. When two or more qubits become entangled, the state of one (no matter how far apart they are) can instantly affect the others; this interconnectedness is critical in quantum error correction protocols to maintain coherence and accuracy during computations.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "\n",
    "llm = Ollama(model=\"phi3\")\n",
    "\n",
    "llm.invoke(\"what is a qubit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a8f49f-62b5-48d8-8607-1a475a1c7544",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9d387cc8-3828-4c21-a0ff-4bb139c30a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'url', 'title', 'text'],\n",
       "    num_rows: 10000\n",
       "})"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data = load_dataset(\"wikipedia\", \"20220301.simple\", split='train[:10000]')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "70ac44e1-5ee0-4788-907d-a90776650a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['ID', 'Joke'],\n",
       "    num_rows: 100000\n",
       "})"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "datajokes = load_dataset(\"ysharma/short_jokes\", split='train[:100000]')\n",
    "datajokes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cce1bdf-3346-4b5f-b0eb-81ba2659027b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '13',\n",
       " 'url': 'https://simple.wikipedia.org/wiki/Alan%20Turing',\n",
       " 'title': 'Alan Turing',\n",
       " 'text': 'Alan Mathison Turing OBE FRS (London, 23 June 1912 – Wilmslow, Cheshire, 7 June 1954) was an English mathematician and computer scientist. He was born in Maida Vale, London.\\n\\nEarly life and family \\nAlan Turing was born in Maida Vale, London on 23 June 1912. His father was part of a family of merchants from Scotland. His mother, Ethel Sara, was the daughter of an engineer.\\n\\nEducation \\nTuring went to St. Michael\\'s, a school at 20 Charles Road, St Leonards-on-sea, when he was five years old.\\n\"This is only a foretaste of what is to come, and only the shadow of what is going to be.” – Alan Turing.\\n\\nThe Stoney family were once prominent landlords, here in North Tipperary. His mother Ethel Sara Stoney (1881–1976) was daughter of Edward Waller Stoney (Borrisokane, North Tipperary) and Sarah Crawford (Cartron Abbey, Co. Longford); Protestant Anglo-Irish gentry.\\n\\nEducated in Dublin at Alexandra School and College; on October 1st 1907 she married Julius Mathison Turing, latter son of Reverend John Robert Turing and Fanny Boyd, in Dublin. Born on June 23rd 1912, Alan Turing would go on to be regarded as one of the greatest figures of the twentieth century.\\n\\nA brilliant mathematician and cryptographer Alan was to become the founder of modern-day computer science and artificial intelligence; designing a machine at Bletchley Park to break secret Enigma encrypted messages used by the Nazi German war machine to protect sensitive commercial, diplomatic and military communications during World War 2. Thus, Turing made the single biggest contribution to the Allied victory in the war against Nazi Germany, possibly saving the lives of an estimated 2 million people, through his effort in shortening World War II.\\n\\nIn 2013, almost 60 years later, Turing received a posthumous Royal Pardon from Queen Elizabeth II. Today, the “Turing law” grants an automatic pardon to men who died before the law came into force, making it possible for living convicted gay men to seek pardons for offences now no longer on the statute book.\\n\\nAlas, Turing accidentally or otherwise lost his life in 1954, having been subjected by a British court to chemical castration, thus avoiding a custodial sentence. He is known to have ended his life at the age of 41 years, by eating an apple laced with cyanide.\\n\\nCareer \\nTuring was one of the people who worked on the first computers. He created the theoretical  Turing machine in 1936. The machine was imaginary, but it included the idea of a computer program.\\n\\nTuring was interested in artificial intelligence. He proposed the Turing test, to say when a machine could be called \"intelligent\". A computer could be said to \"think\" if a human talking with it could not tell it was a machine.\\n\\nDuring World War II, Turing worked with others to break German ciphers (secret messages). He  worked for the Government Code and Cypher School (GC&CS) at Bletchley Park, Britain\\'s codebreaking centre that produced Ultra intelligence.\\nUsing cryptanalysis, he helped to break the codes of the Enigma machine. After that, he worked on other German codes.\\n\\nFrom 1945 to 1947, Turing worked on the design of the ACE (Automatic Computing Engine) at the National Physical Laboratory. He presented a paper on 19 February 1946. That paper was \"the first detailed design of a stored-program computer\". Although it was possible to build ACE, there were delays in starting the project. In late 1947 he returned to Cambridge for a sabbatical year. While he was at Cambridge, the Pilot ACE was built without him. It ran its first program on 10\\xa0May 1950.\\n\\nPrivate life \\nTuring was a homosexual man. In 1952, he admitted having had sex with a man in England. At that time, homosexual acts were illegal. Turing was convicted. He had to choose between going to jail and taking hormones to lower his sex drive. He decided to take the hormones. After his punishment, he became impotent. He also grew breasts.\\n\\nIn May 2012, a private member\\'s bill was put before the House of Lords to grant Turing a statutory pardon. In July 2013, the government supported it. A royal pardon was granted on 24 December 2013.\\n\\nDeath \\nIn 1954, Turing died from cyanide poisoning. The cyanide came from either an apple which was poisoned with cyanide, or from water that had cyanide in it. The reason for the confusion is that the police never tested the apple for cyanide. It is also suspected that he committed suicide.\\n\\nThe treatment forced on him is now believed to be very wrong. It is against medical ethics and international laws of human rights. In August 2009, a petition asking the British Government to apologise to Turing for punishing him for being a homosexual was started. The petition received thousands of signatures. Prime Minister Gordon Brown acknowledged the petition. He called Turing\\'s treatment \"appalling\".\\n\\nReferences\\n\\nOther websites \\nJack Copeland 2012. Alan Turing: The codebreaker who saved \\'millions of lives\\'. BBC News / Technology \\n\\nEnglish computer scientists\\nEnglish LGBT people\\nEnglish mathematicians\\nGay men\\nLGBT scientists\\nScientists from London\\nSuicides by poison\\nSuicides in the United Kingdom\\n1912 births\\n1954 deaths\\nOfficers of the Order of the British Empire'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a2c2fcb7-ec18-4ca1-9f1e-4b28873b4428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ID': 9,\n",
       " 'Joke': \"What do you do if a bird shits on your car? Don't ask her out again.\"}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datajokes[8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728012d2-64df-48a3-9a8d-8b84adc855d3",
   "metadata": {},
   "source": [
    "## Tokenizing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e494fc70-8ea1-47a8-bffa-b37bf5672c58",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Because we cannot tokenize entire wikipediatexts we need to split it first up into chuncks. The jokes are mostly 1 sentence once and can be embedded like they are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a55e1ba-8449-45fa-a9c9-f38d72bb5dce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\")\n",
    "\n",
    "#function textsplitter needs a lenfunction\n",
    "# effective tokenization is done by tokenizer.tokenize(text) (easy peasy)\n",
    "def token_len(text):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    return len(tokens)\n",
    "\n",
    "token_len(\"This is a test sentence to see if token_len gives something that could be true \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afe77dfe-8441-4d5c-b2bd-9a1d4707ad13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#There is a limit on the tokenizer, so we divide the text up in chunks. Important to think about overlap and seperators\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=400,\n",
    "    chunk_overlap=20,\n",
    "    length_function=token_len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f859be9-4f90-43fb-9419-fdee9424452e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d847cb7-b61b-4cf1-ac9d-32db7a86b35d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Alan Mathison Turing OBE FRS (London, 23 June 1912 – Wilmslow, Cheshire, 7 June 1954) was an English mathematician and computer scientist. He was born in Maida Vale, London.\\n\\nEarly life and family \\nAlan Turing was born in Maida Vale, London on 23 June 1912. His father was part of a family of merchants from Scotland. His mother, Ethel Sara, was the daughter of an engineer.\\n\\nEducation \\nTuring went to St. Michael\\'s, a school at 20 Charles Road, St Leonards-on-sea, when he was five years old.\\n\"This is only a foretaste of what is to come, and only the shadow of what is going to be.” – Alan Turing.\\n\\nThe Stoney family were once prominent landlords, here in North Tipperary. His mother Ethel Sara Stoney (1881–1976) was daughter of Edward Waller Stoney (Borrisokane, North Tipperary) and Sarah Crawford (Cartron Abbey, Co. Longford); Protestant Anglo-Irish gentry.\\n\\nEducated in Dublin at Alexandra School and College; on October 1st 1907 she married Julius Mathison Turing, latter son of Reverend John Robert Turing and Fanny Boyd, in Dublin. Born on June 23rd 1912, Alan Turing would go on to be regarded as one of the greatest figures of the twentieth century.',\n",
       " 'A brilliant mathematician and cryptographer Alan was to become the founder of modern-day computer science and artificial intelligence; designing a machine at Bletchley Park to break secret Enigma encrypted messages used by the Nazi German war machine to protect sensitive commercial, diplomatic and military communications during World War 2. Thus, Turing made the single biggest contribution to the Allied victory in the war against Nazi Germany, possibly saving the lives of an estimated 2 million people, through his effort in shortening World War II.\\n\\nIn 2013, almost 60 years later, Turing received a posthumous Royal Pardon from Queen Elizabeth II. Today, the “Turing law” grants an automatic pardon to men who died before the law came into force, making it possible for living convicted gay men to seek pardons for offences now no longer on the statute book.\\n\\nAlas, Turing accidentally or otherwise lost his life in 1954, having been subjected by a British court to chemical castration, thus avoiding a custodial sentence. He is known to have ended his life at the age of 41 years, by eating an apple laced with cyanide.\\n\\nCareer \\nTuring was one of the people who worked on the first computers. He created the theoretical  Turing machine in 1936. The machine was imaginary, but it included the idea of a computer program.\\n\\nTuring was interested in artificial intelligence. He proposed the Turing test, to say when a machine could be called \"intelligent\". A computer could be said to \"think\" if a human talking with it could not tell it was a machine.',\n",
       " 'During World War II, Turing worked with others to break German ciphers (secret messages). He  worked for the Government Code and Cypher School (GC&CS) at Bletchley Park, Britain\\'s codebreaking centre that produced Ultra intelligence.\\nUsing cryptanalysis, he helped to break the codes of the Enigma machine. After that, he worked on other German codes.\\n\\nFrom 1945 to 1947, Turing worked on the design of the ACE (Automatic Computing Engine) at the National Physical Laboratory. He presented a paper on 19 February 1946. That paper was \"the first detailed design of a stored-program computer\". Although it was possible to build ACE, there were delays in starting the project. In late 1947 he returned to Cambridge for a sabbatical year. While he was at Cambridge, the Pilot ACE was built without him. It ran its first program on 10\\xa0May 1950.\\n\\nPrivate life \\nTuring was a homosexual man. In 1952, he admitted having had sex with a man in England. At that time, homosexual acts were illegal. Turing was convicted. He had to choose between going to jail and taking hormones to lower his sex drive. He decided to take the hormones. After his punishment, he became impotent. He also grew breasts.\\n\\nIn May 2012, a private member\\'s bill was put before the House of Lords to grant Turing a statutory pardon. In July 2013, the government supported it. A royal pardon was granted on 24 December 2013.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks = text_splitter.split_text(data[6]['text'])[:3]\n",
    "chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89d686a9-a126-4a29-a574-dd6461803a64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(370, 372, 384)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_len(chunks[0]), token_len(chunks[1]), token_len(chunks[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69297e6d-9638-4367-b14d-ca3810f2d979",
   "metadata": {},
   "source": [
    "## Embeddings: huggingface\n",
    "We choose for the *sentence-transformers/all-MiniLM-l6-v2* embedding now. This is a small, well performing model. Best is to keep an eye out in https://huggingface.co/spaces/mteb/leaderboard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c41333-6735-4393-856e-448162be3632",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "775323c0-dccd-44b5-8eb7-e42f1c0d22b9",
   "metadata": {},
   "source": [
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "231d1fef-a2b7-4ae2-a781-f798bd6a31af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain_huggingface\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "834b93cc-5ac1-4b73-a2c8-10d908eb1263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your HF Inference API Key:\n",
      "\n",
      " ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "\n",
    "inference_api_key = getpass.getpass(\"Enter your HF Inference API Key:\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7d12207f-aaa8-4bf1-a3e6-65752b7a9831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceInferenceAPIEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceInferenceAPIEmbeddings(\n",
    "    api_key=inference_api_key, model_name=\"sentence-transformers/all-MiniLM-l6-v2\"\n",
    ")\n",
    "\n",
    "text = 'I have to poo my pants'\n",
    "query_result = embeddings.embed_query(text) #difference embed_query and embed_documents!!!\n",
    "embed_document = embeddings.embed_documents(text)\n",
    "len(embed_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f89b61c-b8c8-4a61-a3b0-8f194caff963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 384)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [\n",
    "    'this is the first chunk of text', \n",
    "    'and i also still have to poo'\n",
    "]\n",
    "\n",
    "res = embeddings.embed_documents(texts)\n",
    "len(res), len(res[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787ac065-c210-465e-9674-51f88d8571c7",
   "metadata": {},
   "source": [
    "## Vectordatabase: Pinecone\n",
    "\n",
    "Dimensionality must be of used model.\n",
    "\n",
    "We first make and Index and fill the index, only later we fill everything the the vc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ca56b2d-b5cd-467e-ac2e-cc65b9f3808c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pinecone-client in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (5.0.0)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from pinecone-client) (2023.7.22)\n",
      "Requirement already satisfied: pinecone-plugin-inference==1.0.2 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from pinecone-client) (1.0.2)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from pinecone-client) (0.0.7)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from pinecone-client) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from pinecone-client) (4.9.0)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /Users/daanbuseyne/miniconda3/lib/python3.11/site-packages (from pinecone-client) (2.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pinecone-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f02a5bba-d5ef-4278-8ded-b221a4511cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "pc = Pinecone(api_key=\"*******************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893d2f1e-3135-4f30-bfaa-2c2d7f9c881d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "33709ffe-e26a-4a8e-8591-813cef703523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 384,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {},\n",
       " 'total_vector_count': 0}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "index_name = 'jokes'\n",
    "existing_indexes = [\n",
    "    index_info[\"name\"] for index_info in pc.list_indexes()\n",
    "]\n",
    "\n",
    "# check if index already exists (it shouldn't if this is first time)\n",
    "if index_name not in existing_indexes:\n",
    "    \n",
    "    # if does not exist, create index\n",
    "    pc.create_index(\n",
    "        index_name,\n",
    "        dimension=384,  # dimensionality of phi3\n",
    "        metric='cosine',\n",
    "        spec=ServerlessSpec(\n",
    "        cloud=\"aws\",\n",
    "        region=\"us-east-1\"\n",
    "    ))\n",
    "    # wait for index to be initialized\n",
    "    while not pc.describe_index(index_name).status['ready']:\n",
    "        time.sleep(1)\n",
    "\n",
    "# connect to index\n",
    "index = pc.Index(index_name)\n",
    "time.sleep(1)\n",
    "# view index stats\n",
    "index.describe_index_stats() #since we didnt fill these yet here should normally stand 0 total vector count. However, i reran this after filling the vd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8bf1c56d-da7b-4f7b-a554-c3a7d8201437",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|███████████                             | 277/1000 [00:15<00:35, 20.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102 102 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|███████████▍                            | 287/1000 [00:16<00:48, 14.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102 102 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███████████████▋                        | 393/1000 [00:21<00:25, 23.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████████████████▏                       | 404/1000 [00:22<00:35, 16.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n",
      "104 104 104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|██████████████████                      | 452/1000 [00:24<00:22, 24.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104 104 104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|██████████████████████▏                 | 554/1000 [00:30<00:24, 17.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101 101 101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|███████████████████████▎                | 584/1000 [00:32<00:21, 19.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101 101 101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1000/1000 [00:55<00:00, 18.15it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from uuid import uuid4\n",
    "\n",
    "batch_limit = 100\n",
    "counter = 0\n",
    "\n",
    "texts = []\n",
    "metadatas = []\n",
    "\n",
    "for i, record in enumerate(tqdm(data)):\n",
    "    counter += 1\n",
    "    # first get metadata fields for this record\n",
    "    metadata = {\n",
    "        'wiki-id': str(record['id']),\n",
    "        'source': record['url'],\n",
    "        'title': record['title']\n",
    "    }\n",
    "    # now we create chunks from the record text\n",
    "    record_texts = text_splitter.split_text(record['text'])\n",
    "    # create individual metadata dicts for each chunk\n",
    "    record_metadatas = [{\n",
    "        \"chunk\": j, \"text\": text, **metadata\n",
    "    } for j, text in enumerate(record_texts)]\n",
    "    # append these to current batches\n",
    "    texts.extend(record_texts)\n",
    "    metadatas.extend(record_metadatas)\n",
    "    # if we have reached the batch_limit we can add texts\n",
    "    if len(texts) >= batch_limit:\n",
    "    \n",
    "        ids = [str(uuid4()) for _ in range(len(texts))]\n",
    "        embeds = embeddings.embed_documents(texts)\n",
    "        if counter%10 == 0:\n",
    "            print(len(ids), len(embeds), len(texts))\n",
    "        index.upsert(vectors=zip(ids, embeds, metadatas))\n",
    "        \n",
    "        metadatas = []\n",
    "        if counter%10 == 0:\n",
    "            print(len(ids), len(embeds), len(texts))\n",
    "            \n",
    "\n",
    "        texts = []         \n",
    "\n",
    "\n",
    "if len(texts) > 0:\n",
    "    ids = [str(uuid4()) for _ in range(len(texts))]\n",
    "    embeds = embeddings.embed_documents(texts)\n",
    "    index.upsert(vectors=zip(ids, embeds, metadatas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9404a9f0-bc5b-4465-a4d0-78891901b5d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 384,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 3479}},\n",
       " 'total_vector_count': 3479}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "019512d5-4789-45c0-84c0-f87552599d41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66, 66)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ids), len(embeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2feeb261-b24a-4ffb-aa96-545a564a4be1",
   "metadata": {},
   "source": [
    "## Vectorstoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "241de68f-83bc-459b-9c56-4ed399c46293",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Pinecone\n",
    "\n",
    "text_field = \"text\"  # the metadata field that contains our text\n",
    "\n",
    "# initialize the vector store object\n",
    "vectorstore = Pinecone(\n",
    "    index, embeddings.embed_query, text_field\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bce82706-1bc2-4218-b0b4-d46ef61a53fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'chunk': 0.0, 'source': 'https://simple.wikipedia.org/wiki/Albert%20Einstein', 'title': 'Albert Einstein', 'wiki-id': '2138'}, page_content=\"Albert Einstein (14 March 1879 – 18 April 1955) was a German-born American scientist. He worked on theoretical physics. He developed the theory of relativity. He received the Nobel Prize in Physics in 1921 for theoretical physics.\\n\\nHis famous equation is  (E = energy, m = mass, c = speed of light (energy = mass X speed of light²).\\n\\nAt the start of his career, Einstein didn't think that Newtonian mechanics was enough to bring together the laws of classical mechanics and the laws of the electromagnetic field. Between 1902–1909 he made the theory of special relativity to fix it. Einstein also thought that Isaac Newton's idea of gravity was not completely correct. So, he extended his ideas on special relativity to include gravity. In 1916, he published a paper on general relativity with his theory of gravitation.\"),\n",
       " Document(metadata={'chunk': 2.0, 'source': 'https://simple.wikipedia.org/wiki/Albert%20Einstein', 'title': 'Albert Einstein', 'wiki-id': '2138'}, page_content='Life\\n\\nEarly life \\nEinstein was born in Ulm, Württemberg, Germany, on 14 March 1879. His family was Jewish, but was not very religious. However, later in life Einstein became very interested in his Judaism. Einstein did not begin speaking until he was 2 years old. According to his younger sister, Maja, \"He had such difficulty with language that those around him feared he would never learn\". When Einstein was around 4 years old, his father gave him a magnetic compass. He tried hard to understand how the needle could seem to move itself so that it always pointed north. The needle was in a closed case, so clearly nothing like wind could be pushing the needle around, and yet it moved. So in this way Einstein became interested in studying science and mathematics. His compass gave him ideas to explore the world of science.\\n\\nWhen he became older, he went to school in Switzerland. After he graduated, he got a job in the patent office there. While he was working there, he wrote the papers that first made him famous as a great scientist.\\n\\nEinstein married with a 20-year-old Serbian woman Mileva Marić in January 1903.\\n\\nIn 1917, Einstein became very sick with an illness that almost killed him, fortunately he survived. His cousin Elsa Löwenthal nursed him back to health. After this happened, Einstein divorced Mileva in 14 February 1919, and married Elsa on 2 June 1919.'),\n",
       " Document(metadata={'chunk': 19.0, 'source': 'https://simple.wikipedia.org/wiki/Albert%20Einstein', 'title': 'Albert Einstein', 'wiki-id': '2138'}, page_content='References \\n\\n Einstein, Albert and Infeld, Leopold 1938. The evolution of physics: from early concept to relativity and quanta. Cambridge University Press. A non-mathematical account.\\n\\nOther websites \\n\\n What Did Albert Einstein Invent?\\n\\n1879 births\\n1955 deaths\\n \\nCardiovascular disease deaths in the United States\\nDeaths from aortic aneurysm\\nGerman Nobel Prize winners\\nGerman physicists\\nJewish academics\\nJewish American academics\\nJewish American scientists\\nJewish German academics\\nJewish German scientists\\nJewish Nobel Prize winners\\nJewish scientists\\nNaturalized citizens of the United States\\nNobel Prize in Physics winners\\nPeople from Ulm\\nRefugees from Nazism\\nSwiss Jews\\nSwiss scientists\\nAmerican theoretical physicists\\nEducators from New Jersey')]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"who was Einstein?\"\n",
    "\n",
    "\n",
    "vectorstore.similarity_search(\n",
    "    query,  # our search query\n",
    "    k=3  # return 3 most relevant docs\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2ed64c33-6207-4310-a922-4597de583db5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.01577218621969223"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"who was einstein?\"\n",
    "\n",
    "res = embeddings.embed_documents(query)\n",
    "res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e4571d57-68bd-4c41-ba62-429021747c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'chunk': 0.0, 'source': 'https://simple.wikipedia.org/wiki/Albert%20Einstein', 'title': 'Albert Einstein', 'wiki-id': '2138'}, page_content=\"Albert Einstein (14 March 1879 – 18 April 1955) was a German-born American scientist. He worked on theoretical physics. He developed the theory of relativity. He received the Nobel Prize in Physics in 1921 for theoretical physics.\\n\\nHis famous equation is  (E = energy, m = mass, c = speed of light (energy = mass X speed of light²).\\n\\nAt the start of his career, Einstein didn't think that Newtonian mechanics was enough to bring together the laws of classical mechanics and the laws of the electromagnetic field. Between 1902–1909 he made the theory of special relativity to fix it. Einstein also thought that Isaac Newton's idea of gravity was not completely correct. So, he extended his ideas on special relativity to include gravity. In 1916, he published a paper on general relativity with his theory of gravitation.\"),\n",
       " Document(metadata={'chunk': 19.0, 'source': 'https://simple.wikipedia.org/wiki/Albert%20Einstein', 'title': 'Albert Einstein', 'wiki-id': '2138'}, page_content='References \\n\\n Einstein, Albert and Infeld, Leopold 1938. The evolution of physics: from early concept to relativity and quanta. Cambridge University Press. A non-mathematical account.\\n\\nOther websites \\n\\n What Did Albert Einstein Invent?\\n\\n1879 births\\n1955 deaths\\n \\nCardiovascular disease deaths in the United States\\nDeaths from aortic aneurysm\\nGerman Nobel Prize winners\\nGerman physicists\\nJewish academics\\nJewish American academics\\nJewish American scientists\\nJewish German academics\\nJewish German scientists\\nJewish Nobel Prize winners\\nJewish scientists\\nNaturalized citizens of the United States\\nNobel Prize in Physics winners\\nPeople from Ulm\\nRefugees from Nazism\\nSwiss Jews\\nSwiss scientists\\nAmerican theoretical physicists\\nEducators from New Jersey'),\n",
       " Document(metadata={'chunk': 4.0, 'source': 'https://simple.wikipedia.org/wiki/Albert%20Einstein', 'title': 'Albert Einstein', 'wiki-id': '2138'}, page_content='Later life \\nIn spring of 1914, he moved back to Germany, and became ordinary member of the Prussian Academy and director of a newly established institute for physics of the Kaiser-Wilhelm-Gesellschaft. He lived in Berlin and finished the General Theory of Relativity in November 1915. In the Weimar Republic, he was politically active for socialism and Zionism. In 1922, he received the Nobel prize for Physics for his explanation of the photoelectric effect in 1905. He then tried to formulate a general field theory uniting gravitation and electromagnetism, without success. He had reservations about the quantum mechanics invented by Heisenberg (1925) and Schrödinger (1926). In spring of 1933, Einstein and Elsa were traveling in the USA when the Nazi party came to power. The Nazis were violently antisemitic. They called  Einstein\\'s relativity theory  \"Jewish physics,\" and some German physicists started polemics against his theories. Others, like Planck and Heisenberg, defended Einstein.\\n\\nAfter their return to Belgium, considering the threats from the Nazis, Einstein resigned from his position in the Prussian Academy in a letter from Oostende. Einstein and Elsa decided not to go back to Berlin and moved to Princeton, New Jersey in the United States, and in 1940 he became a United States citizen.')]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "query = \"who was Albert Einstein?\"\n",
    "\n",
    "vectorstore.similarity_search(\n",
    "    query,  # our search query\n",
    "    k=3  # return 3 most relevant docs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5577f2d5-a087-42ca-a750-f7755805591a",
   "metadata": {},
   "source": [
    "## QandA Retrieval\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3433ae-a5e9-4e98-9076-267922d841ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7bdbb153-be5b-4c5d-90f0-c398a33e49f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectorstore.as_retriever()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "da967ccf-db47-4c39-bac5-350b29c105d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daanbuseyne/miniconda3/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Albert Einstein was a German-born American scientist recognized for his groundbreaking work in theoretical physics, particularly the development of the theory of relativity and contributions to quantum mechanics with his explanation of the photoelectric effect. Born on March 14, 1879, in Ulm, Germany, Einstein received international fame after he developed a famous equation E=mc², which reveals the equivalence of mass (m) and energy (E), where c is the speed of light squared. He later extended his ideas to include gravity as part of this unified theory but faced challenges in reconciling general relativity with quantum mechanics, two pillars of modern physics that are still not fully integrated today. Einstein was a vocal advocate for socialism and Zionism during the Weimar Republic before migrating to America due to increasing antisemitic sentiments under Nazi rule; he became an American citizen in 1940 and spent his later life at Princeton, New Jersey.'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bdafc283-5acd-4cf3-8966-cb736fe83a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "\n",
    "qa_with_sources = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    return_source_documents=True,\n",
    "    retriever=vectorstore.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d20d8ebb-be45-458a-9e89-1bd6a0c2d189",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daanbuseyne/miniconda3/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'who was Albert Einstein?',\n",
       " 'answer': 'In the later years of his life, Albert Einstein resigned from his position in the Prussian Academy after returning to Germany during spring of 1914. As he completed The General Theory of Relativity, Nazi Party came into power which caused antisemitism towards Jews and called for a rejection against relativity theory as \"Jewish physics.\" Due to these threats, Einstein decided not to go back to Berlin with Elsa, moving instead to Belgium. In 1940, he became an American citizen after being offered this option when returning from the United States during World War II. Albert Einstein\\'s life journey began in Ulm, Württemberg, Germany on March 14, 1879 and ended with his death in Princeton, New Jersey in 1955 due to aortic aneurysm caused by cardiovascular disease after spending the first four years of life learning about science from everyday items. He was married twice - Mileva Marić initially at age 24 and then Elsa Löwenthal later in 1919, following a health scare which made him divorce his initial wife.',\n",
       " 'sources': '',\n",
       " 'source_documents': [Document(metadata={'chunk': 0.0, 'source': 'https://simple.wikipedia.org/wiki/Albert%20Einstein', 'title': 'Albert Einstein', 'wiki-id': '2138'}, page_content=\"Albert Einstein (14 March 1879 – 18 April 1955) was a German-born American scientist. He worked on theoretical physics. He developed the theory of relativity. He received the Nobel Prize in Physics in 1921 for theoretical physics.\\n\\nHis famous equation is  (E = energy, m = mass, c = speed of light (energy = mass X speed of light²).\\n\\nAt the start of his career, Einstein didn't think that Newtonian mechanics was enough to bring together the laws of classical mechanics and the laws of the electromagnetic field. Between 1902–1909 he made the theory of special relativity to fix it. Einstein also thought that Isaac Newton's idea of gravity was not completely correct. So, he extended his ideas on special relativity to include gravity. In 1916, he published a paper on general relativity with his theory of gravitation.\"),\n",
       "  Document(metadata={'chunk': 19.0, 'source': 'https://simple.wikipedia.org/wiki/Albert%20Einstein', 'title': 'Albert Einstein', 'wiki-id': '2138'}, page_content='References \\n\\n Einstein, Albert and Infeld, Leopold 1938. The evolution of physics: from early concept to relativity and quanta. Cambridge University Press. A non-mathematical account.\\n\\nOther websites \\n\\n What Did Albert Einstein Invent?\\n\\n1879 births\\n1955 deaths\\n \\nCardiovascular disease deaths in the United States\\nDeaths from aortic aneurysm\\nGerman Nobel Prize winners\\nGerman physicists\\nJewish academics\\nJewish American academics\\nJewish American scientists\\nJewish German academics\\nJewish German scientists\\nJewish Nobel Prize winners\\nJewish scientists\\nNaturalized citizens of the United States\\nNobel Prize in Physics winners\\nPeople from Ulm\\nRefugees from Nazism\\nSwiss Jews\\nSwiss scientists\\nAmerican theoretical physicists\\nEducators from New Jersey'),\n",
       "  Document(metadata={'chunk': 4.0, 'source': 'https://simple.wikipedia.org/wiki/Albert%20Einstein', 'title': 'Albert Einstein', 'wiki-id': '2138'}, page_content='Later life \\nIn spring of 1914, he moved back to Germany, and became ordinary member of the Prussian Academy and director of a newly established institute for physics of the Kaiser-Wilhelm-Gesellschaft. He lived in Berlin and finished the General Theory of Relativity in November 1915. In the Weimar Republic, he was politically active for socialism and Zionism. In 1922, he received the Nobel prize for Physics for his explanation of the photoelectric effect in 1905. He then tried to formulate a general field theory uniting gravitation and electromagnetism, without success. He had reservations about the quantum mechanics invented by Heisenberg (1925) and Schrödinger (1926). In spring of 1933, Einstein and Elsa were traveling in the USA when the Nazi party came to power. The Nazis were violently antisemitic. They called  Einstein\\'s relativity theory  \"Jewish physics,\" and some German physicists started polemics against his theories. Others, like Planck and Heisenberg, defended Einstein.\\n\\nAfter their return to Belgium, considering the threats from the Nazis, Einstein resigned from his position in the Prussian Academy in a letter from Oostende. Einstein and Elsa decided not to go back to Berlin and moved to Princeton, New Jersey in the United States, and in 1940 he became a United States citizen.'),\n",
       "  Document(metadata={'chunk': 2.0, 'source': 'https://simple.wikipedia.org/wiki/Albert%20Einstein', 'title': 'Albert Einstein', 'wiki-id': '2138'}, page_content='Life\\n\\nEarly life \\nEinstein was born in Ulm, Württemberg, Germany, on 14 March 1879. His family was Jewish, but was not very religious. However, later in life Einstein became very interested in his Judaism. Einstein did not begin speaking until he was 2 years old. According to his younger sister, Maja, \"He had such difficulty with language that those around him feared he would never learn\". When Einstein was around 4 years old, his father gave him a magnetic compass. He tried hard to understand how the needle could seem to move itself so that it always pointed north. The needle was in a closed case, so clearly nothing like wind could be pushing the needle around, and yet it moved. So in this way Einstein became interested in studying science and mathematics. His compass gave him ideas to explore the world of science.\\n\\nWhen he became older, he went to school in Switzerland. After he graduated, he got a job in the patent office there. While he was working there, he wrote the papers that first made him famous as a great scientist.\\n\\nEinstein married with a 20-year-old Serbian woman Mileva Marić in January 1903.\\n\\nIn 1917, Einstein became very sick with an illness that almost killed him, fortunately he survived. His cousin Elsa Löwenthal nursed him back to health. After this happened, Einstein divorced Mileva in 14 February 1919, and married Elsa on 2 June 1919.')]}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_with_sources(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b20c3137-7d4c-40b1-a2b6-14f7a3a035d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Can you tell me about the history of Belgium?\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99149a1-8025-409d-aa32-4193699b96b1",
   "metadata": {},
   "source": [
    "## Jokes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f5724c-47f5-4d12-a6f2-ded0ba99c461",
   "metadata": {},
   "source": [
    "We will use a similar approach to use RAG for the purpose of joke generation. Now we need to use a new pinecone index (most wikipedia pages are not that funny). We also only uses the joke id as meta data. Some additional changes are that we do not need to split the jokes since they are small enough to be embedded directly and the meaning/punchline could get lost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "fde86365-bf6f-4a88-b254-2645b7299849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 384,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {},\n",
       " 'total_vector_count': 0}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "index_name = 'jokes'\n",
    "existing_indexes = [\n",
    "    index_info[\"name\"] for index_info in pc.list_indexes()\n",
    "]\n",
    "\n",
    "# check if index already exists (it shouldn't if this is first time)\n",
    "if index_name not in existing_indexes:\n",
    "    \n",
    "    # if does not exist, create index\n",
    "    pc.create_index(\n",
    "        index_name,\n",
    "        dimension=384,  # dimensionality of phi3\n",
    "        metric='cosine',\n",
    "        spec=ServerlessSpec(\n",
    "        cloud=\"aws\",\n",
    "        region=\"us-east-1\"\n",
    "    ))\n",
    "    # wait for index to be initialized\n",
    "    while not pc.describe_index(index_name).status['ready']:\n",
    "        time.sleep(1)\n",
    "\n",
    "# connect to index\n",
    "index = pc.Index(index_name)\n",
    "time.sleep(1)\n",
    "# view index stats\n",
    "index.describe_index_stats() #since we didnt fill these yet here should normally stand 0 total vector count. However, i reran this after filling the vd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8980d194-17ae-40f8-ac61-ee29e9c116c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "7cdedc06-e9f8-4fbb-9396-ad4dc2cbfc74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                   | 300/100000 [03:14<17:59:59,  1.54it/s]\n"
     ]
    },
    {
     "ename": "ListConversionException",
     "evalue": "Expected a list or list-like data structure, but got: error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mListConversionException\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[118], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m ids \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mstr\u001b[39m(uuid4()) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(texts))]\n\u001b[1;32m     28\u001b[0m embeds \u001b[38;5;241m=\u001b[39m embeddings\u001b[38;5;241m.\u001b[39membed_documents(texts)\n\u001b[0;32m---> 30\u001b[0m \u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvectors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m metadatas \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     33\u001b[0m texts \u001b[38;5;241m=\u001b[39m []         \n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pinecone/utils/error_handling.py:11\u001b[0m, in \u001b[0;36mvalidate_and_convert_errors.<locals>.inner_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner_func\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 11\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m MaxRetryError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, ProtocolError):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pinecone/data/index.py:175\u001b[0m, in \u001b[0;36mIndex.upsert\u001b[0;34m(self, vectors, namespace, batch_size, show_progress, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    169\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masync_req is not supported when batch_size is provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo upsert in parallel, please follow: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    171\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://docs.pinecone.io/docs/insert-data#sending-upserts-in-parallel\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    172\u001b[0m     )\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_upsert_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvectors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_check_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(batch_size, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m batch_size \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size must be a positive integer\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pinecone/data/index.py:206\u001b[0m, in \u001b[0;36mIndex._upsert_batch\u001b[0;34m(self, vectors, namespace, _check_type, **kwargs)\u001b[0m\n\u001b[1;32m    201\u001b[0m args_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_non_empty_args([(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnamespace\u001b[39m\u001b[38;5;124m\"\u001b[39m, namespace)])\n\u001b[1;32m    202\u001b[0m vec_builder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m v: VectorFactory\u001b[38;5;241m.\u001b[39mbuild(v, check_type\u001b[38;5;241m=\u001b[39m_check_type)\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vector_api\u001b[38;5;241m.\u001b[39mupsert(\n\u001b[1;32m    205\u001b[0m     UpsertRequest(\n\u001b[0;32m--> 206\u001b[0m         vectors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(vec_builder, vectors)),\n\u001b[1;32m    207\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39margs_dict,\n\u001b[1;32m    208\u001b[0m         _check_type\u001b[38;5;241m=\u001b[39m_check_type,\n\u001b[1;32m    209\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m _OPENAPI_ENDPOINT_PARAMS},\n\u001b[1;32m    210\u001b[0m     ),\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m _OPENAPI_ENDPOINT_PARAMS},\n\u001b[1;32m    212\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pinecone/data/index.py:202\u001b[0m, in \u001b[0;36mIndex._upsert_batch.<locals>.<lambda>\u001b[0;34m(v)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_upsert_batch\u001b[39m(\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    196\u001b[0m     vectors: Union[List[Vector], List[\u001b[38;5;28mtuple\u001b[39m], List[\u001b[38;5;28mdict\u001b[39m]],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    200\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m UpsertResponse:\n\u001b[1;32m    201\u001b[0m     args_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_non_empty_args([(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnamespace\u001b[39m\u001b[38;5;124m\"\u001b[39m, namespace)])\n\u001b[0;32m--> 202\u001b[0m     vec_builder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m v: \u001b[43mVectorFactory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_check_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vector_api\u001b[38;5;241m.\u001b[39mupsert(\n\u001b[1;32m    205\u001b[0m         UpsertRequest(\n\u001b[1;32m    206\u001b[0m             vectors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(vec_builder, vectors)),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m _OPENAPI_ENDPOINT_PARAMS},\n\u001b[1;32m    212\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pinecone/data/vector_factory.py:26\u001b[0m, in \u001b[0;36mVectorFactory.build\u001b[0;34m(item, check_type)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m item\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVectorFactory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tuple_to_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, Mapping):\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m VectorFactory\u001b[38;5;241m.\u001b[39m_dict_to_vector(item, check_type)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pinecone/data/vector_factory.py:44\u001b[0m, in \u001b[0;36mVectorFactory._tuple_to_vector\u001b[0;34m(item, check_type)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSparse values are not supported in tuples. Please use either dicts or Vector objects as inputs.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     40\u001b[0m     )\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Vector(\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mid\u001b[39m,\n\u001b[0;32m---> 44\u001b[0m         values\u001b[38;5;241m=\u001b[39m\u001b[43mconvert_to_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     45\u001b[0m         metadata\u001b[38;5;241m=\u001b[39mmetadata \u001b[38;5;129;01mor\u001b[39;00m {},\n\u001b[1;32m     46\u001b[0m         _check_type\u001b[38;5;241m=\u001b[39mcheck_type,\n\u001b[1;32m     47\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pinecone/utils/convert_to_list.py:14\u001b[0m, in \u001b[0;36mconvert_to_list\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# The string and dictionary classes in python can be passed to list()\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# but they're not going to yield sensible results for our use case.\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ListConversionException(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected a list or list-like data structure, but got: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mListConversionException\u001b[0m: Expected a list or list-like data structure, but got: error"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from uuid import uuid4\n",
    "\n",
    "batch_limit = 1\n",
    "\n",
    "texts = []\n",
    "metadatas = []\n",
    "\n",
    "for i, record in enumerate(tqdm(datajokes)):\n",
    "    # first get metadata fields for this record\n",
    "    metadata = {\n",
    "        'wiki-id': str(record['ID']),\n",
    "    }\n",
    "    # now we create chunks from the record text\n",
    "    record_texts = [record['Joke']]\n",
    "    # create individual metadata dicts for each chunk\n",
    "    record_metadatas = [{\n",
    "        \"chunk\": j, \"Joke\": text, **metadata\n",
    "    } for j, text in enumerate(record_texts)]\n",
    "    # append these to current batches\n",
    "    texts.extend(record_texts)\n",
    "    metadatas.extend(record_metadatas)\n",
    "    # if we have reached the batch_limit we can add texts\n",
    "    \n",
    "    if len(texts) >= batch_limit:\n",
    "    \n",
    "        ids = [str(uuid4()) for _ in range(len(texts))]\n",
    "        embeds = embeddings.embed_documents(texts)\n",
    "        \n",
    "        index.upsert(vectors=zip(ids, embeds, metadatas))\n",
    "        \n",
    "        metadatas = []\n",
    "        texts = []         \n",
    "\n",
    "\n",
    "if len(texts) > 0:\n",
    "    ids = [str(uuid4()) for _ in range(len(texts))]\n",
    "    embeds = embeddings.embed_documents(texts)\n",
    "    index.upsert(vectors=zip(ids, embeds, metadatas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1caf8360-c163-459c-865b-8b73987a0a1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 384,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 338}},\n",
       " 'total_vector_count': 338}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "41de7c11-9162-443f-8e5d-5bdbac4b40b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': 'Rate limit reached. You reached free usage limit (reset hourly). Please subscribe to a plan at https://huggingface.co/pricing to use the API at this rate'}\n"
     ]
    }
   ],
   "source": [
    "print(embeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc4ae9a-b725-4751-b93d-4251c3561735",
   "metadata": {},
   "source": [
    "# vectorstoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f2d42847-8382-49ea-98d7-00712a5cd60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daanbuseyne/miniconda3/lib/python3.11/site-packages/langchain_community/vectorstores/pinecone.py:68: UserWarning: Passing in `embedding` as a Callable is deprecated. Please pass in an Embeddings object instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Pinecone\n",
    "\n",
    "text_field = \"text\"  # the metadata field that contains our text\n",
    "\n",
    "# initialize the vector store object\n",
    "vectorstore = Pinecone(\n",
    "    index, embeddings.embed_query, text_field\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9fc2ce67-eb10-4d4f-9945-4c10a87b3bb1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[127], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjoke about musicians\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mvectorstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# our search query\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# return 3 most relevant docs\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/langchain_community/vectorstores/pinecone.py:234\u001b[0m, in \u001b[0;36mPinecone.similarity_search\u001b[0;34m(self, query, k, filter, namespace, **kwargs)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msimilarity_search\u001b[39m(\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    217\u001b[0m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    222\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[1;32m    223\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return pinecone documents most similar to query.\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \n\u001b[1;32m    225\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;124;03m        List of Documents most similar to the query and score for each\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 234\u001b[0m     docs_and_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search_with_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnamespace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [doc \u001b[38;5;28;01mfor\u001b[39;00m doc, _ \u001b[38;5;129;01min\u001b[39;00m docs_and_scores]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/langchain_community/vectorstores/pinecone.py:180\u001b[0m, in \u001b[0;36mPinecone.similarity_search_with_score\u001b[0;34m(self, query, k, filter, namespace)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msimilarity_search_with_score\u001b[39m(\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    163\u001b[0m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    166\u001b[0m     namespace: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    167\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Tuple[Document, \u001b[38;5;28mfloat\u001b[39m]]:\n\u001b[1;32m    168\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return pinecone documents most similar to query, along with scores.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \n\u001b[1;32m    170\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;124;03m        List of Documents most similar to the query and score for each\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimilarity_search_by_vector_with_score(\n\u001b[0;32m--> 180\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embed_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m, k\u001b[38;5;241m=\u001b[39mk, \u001b[38;5;28mfilter\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfilter\u001b[39m, namespace\u001b[38;5;241m=\u001b[39mnamespace\n\u001b[1;32m    181\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/langchain_community/vectorstores/pinecone.py:99\u001b[0m, in \u001b[0;36mPinecone._embed_query\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding, Embeddings):\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding\u001b[38;5;241m.\u001b[39membed_query(text)\n\u001b[0;32m---> 99\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/langchain_community/embeddings/huggingface.py:432\u001b[0m, in \u001b[0;36mHuggingFaceInferenceAPIEmbeddings.embed_query\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21membed_query\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m    424\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute query embeddings using a HuggingFace transformer model.\u001b[39;00m\n\u001b[1;32m    425\u001b[0m \n\u001b[1;32m    426\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;124;03m        Embeddings for the text.\u001b[39;00m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 432\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "query = \"joke about musicians\"\n",
    "\n",
    "\n",
    "vectorstore.similarity_search(\n",
    "    query,  # our search query\n",
    "    k=1  # return 3 most relevant docs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a5582b-a2e9-4bbd-a5a8-ccf3a49b3978",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
